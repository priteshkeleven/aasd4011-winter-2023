{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "Tensorboard is the most popular tool for tracking the training of neural networks in either Tensorflow or PyTorch. In fact, it can be used as a visualization tool for many types of data-logs.\n",
    "In this notebook we see how to work with Tensorboard while using PyTorch, and we will review most of the types of data that can be logged for visualization in Tensorboard.\n",
    "\n",
    "In this notebook we will demonstrate how to use _Tensorboard_ for tracking the training. We pick-up from where we left the linear regression problem with the `nn.Module`. \n",
    "\n",
    "#### Optional Resources\n",
    "\n",
    "* [Tensorboard Homepage](https://www.tensorflow.org/tensorboard)\n",
    "* [Tensorboard.dev](https://tensorboard.dev/) - a service by Google, which allows to freely (and _publicly_) share Tensorboard dashboards.\n",
    "\n",
    "PyTorch tutorials about Tensorboard integration:\n",
    "* https://pytorch.org/docs/stable/tensorboard.html\n",
    "* https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n",
    "* https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Pytorch Tensorboard writer\n",
    "* This requires Tensorboard to be installed (via `pip install`). In this repository we install it as part of the `requirements.txt` files.\n",
    "* Tensorflow supports tracking and reporting of: scalars, images, histograms, graphs, and embedding visualizations.\n",
    "* The `SummaryWriter` class is the main entry point to log data for consumption and visualization by TensorBoard.\n",
    "* `SummaryWriter` is writing the data every time it is called. Commonly, this takes place every given number of training iterations. This way, Tensorflow can show data as it is being generated during the training. By the way, it updates the file contents asynchronously. This allows a training program to call methods to add data to the file directly from the training loop, without slowing down training.\n",
    "* For more information see: [Tensorboard with PyTorch](https://pytorch.org/docs/stable/tensorboard.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are running dummy experiments.\n",
    "The first thing we notice is that Tensorboard can consume information that is saved to disk in the right format, Tensorboard will be able to present it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/dummy_experiment')  # default `log_dir` is \"runs\" - we'll be more specific here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we review the many data types that can be logged for visualization with Tensorboard. Make sure to open Tensorboard, and view the generated output following the execution of each cell. This can be done via a Web Browser or directly within VSCode if that's your IDE. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `add_scalar`\n",
    "Note: notice that the `writer` writes is called on every iteration. When implemented this way as part of a training loop, the data is continuously written to disk, and is presentable in Tensorboard in near real-time. Caveat - note that the Tensorboard might need to be refreshed, or the data might not be immediatly written. To force a write (which is usually not needed) the `flush` method can be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_iter in range(100):\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(100)\n",
    "for i in x:\n",
    "    writer.add_scalar('y=2x', i * 2, i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `add_scalars`\n",
    "This call adds three values to the same scalar plot with the tag 'run_14h' in TensorBoard's scalar section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 5\n",
    "for i in range(100):\n",
    "    writer.add_scalars('run_14h', {'xsinx':i*np.sin(i/r),\n",
    "                                    'xcosx':i*np.cos(i/r),\n",
    "                                    'tanx': np.tan(i/r)}, i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `add_histogram`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "for i in range(10):\n",
    "    x = np.random.random(1000)\n",
    "    writer.add_histogram('distribution centers', x + i, i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `add_image`\n",
    "See [Tensorboard with PyTorch](https://pytorch.org/docs/stable/tensorboard.html) for input convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((3, 100, 100))\n",
    "img[0] = np.arange(0, 10000).reshape(100, 100) / 10000\n",
    "img[1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000\n",
    "\n",
    "writer.add_image('my_image', img, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `add_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_text(tag='lstm', text_string='This is an lstm', global_step=0)\n",
    "writer.add_text(tag='rnn', text_string='This is an rnn', global_step=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `add_embeddings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "import keyword\n",
    "\n",
    "meta = []\n",
    "while len(meta)<100:\n",
    "    meta = meta+keyword.kwlist # get some strings\n",
    "meta = meta[:100]\n",
    "\n",
    "for i, v in enumerate(meta):\n",
    "    meta[i] = v+str(i)\n",
    "\n",
    "label_img = torch.rand(100, 3, 10, 32)\n",
    "for i in range(100):\n",
    "    label_img[i]*=i/100.0\n",
    "\n",
    "writer.add_embedding(torch.randn(100, 5), metadata=meta, label_img=label_img)\n",
    "writer.add_embedding(torch.randn(100, 5), label_img=label_img)\n",
    "writer.add_embedding(torch.randn(100, 5), metadata=meta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `add_pr_curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.random.randint(2, size=100)  # binary label\n",
    "predictions = np.random.rand(100)\n",
    "writer = SummaryWriter()\n",
    "writer.add_pr_curve('pr_curve', labels, predictions, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `add_hparams`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SummaryWriter() as w:\n",
    "    for i in range(5):\n",
    "        w.add_hparams({'lr': 0.1*i, 'bsize': i},\n",
    "                      {'hparam/accuracy': 10*i, 'hparam/loss': 10*i})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `add_graph`\n",
    "\n",
    "`add_graph` accepts a [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) as its `Model` argument. \n",
    "Let's define one so that we are able to watch the resulting computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model=model, input_to_model=torch.rand(1, 28*28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Types of Data Loggers\n",
    "\n",
    "Notably, using PyTorch `SummaryWriter` it is possible to log to Tensorboard video and audio clips as well (by using `add_video` and `add_audio`).\n",
    "For a complete and up-to-date list of all data types that can be logged, see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's always a good idea to close the writer when done using it\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cpu",
   "language": "python",
   "name": "pytorch_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2adf6fb4fb9c4fb4fabaad9b8bc3c077a4c74c345da177b977e5e0ddd0495e5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
